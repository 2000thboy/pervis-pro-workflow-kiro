#!/usr/bin/env python3
"""
ä¿®å¤ç´ æå¤„ç†é—®é¢˜
é‡æ–°å¤„ç†ç°æœ‰ç´ æå¹¶å»ºç«‹å‘é‡ç´¢å¼•
"""

import requests
import json
import os
import sqlite3
from pathlib import Path

BASE_URL = "http://localhost:8000"

def get_failed_assets():
    """è·å–å¤„ç†å¤±è´¥çš„ç´ æ"""
    print("ğŸ” æŸ¥æ‰¾å¤„ç†å¤±è´¥çš„ç´ æ...")
    
    db_path = "backend/pervis_director.db"
    if not os.path.exists(db_path):
        print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
        return []
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, filename, processing_status 
            FROM assets 
            WHERE processing_status = 'error' OR processing_status = 'uploaded'
            ORDER BY created_at DESC
        """)
        
        failed_assets = cursor.fetchall()
        conn.close()
        
        print(f"   å‘ç° {len(failed_assets)} ä¸ªéœ€è¦é‡æ–°å¤„ç†çš„ç´ æ")
        return failed_assets
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        return []

def reprocess_asset(asset_id, filename):
    """é‡æ–°å¤„ç†å•ä¸ªç´ æ"""
    print(f"ğŸ”„ é‡æ–°å¤„ç†ç´ æ: {filename}")
    
    try:
        # è°ƒç”¨æ‰¹é‡å¤„ç†API
        response = requests.post(
            f"{BASE_URL}/api/batch/process/asset/{asset_id}",
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"   âœ… å¤„ç†ä»»åŠ¡å·²æäº¤: {result.get('task_id')}")
            return result.get('task_id')
        else:
            print(f"   âŒ å¤„ç†å¤±è´¥: {response.status_code}")
            print(f"      é”™è¯¯: {response.text}")
            return None
            
    except Exception as e:
        print(f"   âŒ å¤„ç†å¼‚å¸¸: {e}")
        return None

def check_processing_status(task_id):
    """æ£€æŸ¥å¤„ç†çŠ¶æ€"""
    if not task_id:
        return None
    
    try:
        response = requests.get(f"{BASE_URL}/api/batch/task/{task_id}", timeout=5)
        
        if response.status_code == 200:
            return response.json()
        else:
            return None
            
    except Exception as e:
        return None

def trigger_vector_indexing():
    """è§¦å‘å‘é‡ç´¢å¼•é‡å»º"""
    print("\nğŸ” è§¦å‘å‘é‡ç´¢å¼•é‡å»º...")
    
    try:
        # è·å–æ‰€æœ‰å·²å¤„ç†çš„ç´ æ
        db_path = "backend/pervis_director.db"
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, filename 
            FROM assets 
            WHERE processing_status = 'completed'
        """)
        
        completed_assets = cursor.fetchall()
        conn.close()
        
        print(f"   å‘ç° {len(completed_assets)} ä¸ªå·²å®Œæˆå¤„ç†çš„ç´ æ")
        
        # ä¸ºæ¯ä¸ªç´ æåˆ›å»ºå‘é‡ç´¢å¼•
        for asset_id, filename in completed_assets:
            print(f"   ä¸º {filename} åˆ›å»ºå‘é‡ç´¢å¼•...")
            
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å‘é‡åŒ–APIï¼Œä½†ç”±äºAPIå¯èƒ½ä¸å­˜åœ¨ï¼Œæˆ‘ä»¬å…ˆè·³è¿‡
            # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨è¯­ä¹‰æœç´¢å¼•æ“æ¥åˆ›å»ºå‘é‡
            pass
        
        return True
        
    except Exception as e:
        print(f"âŒ å‘é‡ç´¢å¼•é‡å»ºå¤±è´¥: {e}")
        return False

def test_multimodal_search_with_mock_data():
    """ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•å¤šæ¨¡æ€æœç´¢"""
    print("\nğŸ§ª æµ‹è¯•å¤šæ¨¡æ€æœç´¢åŠŸèƒ½...")
    
    # ç”±äºå‘é‡ç´¢å¼•ä¸ºç©ºï¼Œæœç´¢ç»“æœä¸º0æ˜¯æ­£å¸¸çš„
    # è®©æˆ‘ä»¬æµ‹è¯•æœç´¢å¼•æ“çš„åŸºç¡€åŠŸèƒ½
    
    test_queries = [
        {
            "query": "åŠ¨æ¼«å°‘å¥³ æ¨±èŠ± æ ¡å›­",
            "search_modes": ["semantic"],
            "limit": 5
        },
        {
            "query": "å¤œæ™š åŸå¸‚ éœ“è™¹ç¯",
            "search_modes": ["semantic", "visual"],
            "weights": {"semantic": 0.6, "visual": 0.4},
            "limit": 5
        }
    ]
    
    for i, query_data in enumerate(test_queries, 1):
        print(f"   æµ‹è¯•æŸ¥è¯¢ {i}: {query_data['query']}")
        
        try:
            response = requests.post(
                f"{BASE_URL}/api/multimodal/search",
                json=query_data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"     âœ… æœç´¢å¼•æ“å“åº”æ­£å¸¸")
                print(f"        æŸ¥è¯¢æ„å›¾: {result['query_intent']['primary_intent']}")
                print(f"        å¤„ç†æ—¶é—´: {result.get('search_time', 0):.3f}ç§’")
                print(f"        ç»“æœæ•°é‡: {result['total_matches']}")
            else:
                print(f"     âŒ æœç´¢å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"     âŒ æœç´¢å¼‚å¸¸: {e}")

def create_sample_vectors():
    """åˆ›å»ºç¤ºä¾‹å‘é‡æ•°æ®ç”¨äºæµ‹è¯•"""
    print("\nğŸ“ åˆ›å»ºç¤ºä¾‹å‘é‡æ•°æ®...")
    
    try:
        # ç›´æ¥åœ¨æ•°æ®åº“ä¸­æ’å…¥ä¸€äº›ç¤ºä¾‹å‘é‡æ•°æ®
        db_path = "backend/pervis_director.db"
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–ä¸€ä¸ªå·²å­˜åœ¨çš„asset_id
        cursor.execute("SELECT id FROM assets LIMIT 1")
        result = cursor.fetchone()
        
        if not result:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ç´ æID")
            conn.close()
            return False
        
        asset_id = result[0]
        
        # åˆ›å»ºç¤ºä¾‹å‘é‡æ•°æ®
        sample_vectors = [
            {
                "id": f"vector_{asset_id}_1",
                "asset_id": asset_id,
                "vector_data": json.dumps([0.1] * 384),  # æ¨¡æ‹Ÿ384ç»´å‘é‡
                "content_type": "description",
                "text_content": "åŠ¨æ¼«é£æ ¼çš„æ ¡å›­åœºæ™¯ï¼Œæ¨±èŠ±é£èˆ"
            },
            {
                "id": f"vector_{asset_id}_2", 
                "asset_id": asset_id,
                "vector_data": json.dumps([0.2] * 384),
                "content_type": "tags",
                "text_content": "æ ¡å›­ æ¨±èŠ± åŠ¨æ¼« å°‘å¥³ é’æ˜¥"
            }
        ]
        
        for vector_data in sample_vectors:
            cursor.execute("""
                INSERT OR REPLACE INTO asset_vectors 
                (id, asset_id, vector_data, content_type, text_content, created_at)
                VALUES (?, ?, ?, ?, ?, datetime('now'))
            """, (
                vector_data["id"],
                vector_data["asset_id"], 
                vector_data["vector_data"],
                vector_data["content_type"],
                vector_data["text_content"]
            ))
        
        conn.commit()
        conn.close()
        
        print(f"   âœ… åˆ›å»ºäº† {len(sample_vectors)} ä¸ªç¤ºä¾‹å‘é‡")
        return True
        
    except Exception as e:
        print(f"   âŒ åˆ›å»ºç¤ºä¾‹å‘é‡å¤±è´¥: {e}")
        return False

def main():
    """ä¸»ä¿®å¤æµç¨‹"""
    print("ğŸ”§ Pervis PRO ç´ æå¤„ç†ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    # 1. æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    try:
        health_response = requests.get(f"{BASE_URL}/api/health", timeout=5)
        if health_response.status_code != 200:
            print("âŒ åç«¯æœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡")
            return
    except:
        print("âŒ æ— æ³•è¿æ¥åç«¯æœåŠ¡")
        return
    
    print("âœ… åç«¯æœåŠ¡è¿è¡Œæ­£å¸¸")
    
    # 2. æŸ¥æ‰¾å¤±è´¥çš„ç´ æ
    failed_assets = get_failed_assets()
    
    if not failed_assets:
        print("âœ… æ²¡æœ‰å‘ç°å¤„ç†å¤±è´¥çš„ç´ æ")
    else:
        # 3. é‡æ–°å¤„ç†å¤±è´¥çš„ç´ æ
        print(f"\nğŸ”„ å¼€å§‹é‡æ–°å¤„ç† {len(failed_assets)} ä¸ªç´ æ...")
        
        task_ids = []
        for asset_id, filename, status in failed_assets[:3]:  # åªå¤„ç†å‰3ä¸ª
            task_id = reprocess_asset(asset_id, filename)
            if task_id:
                task_ids.append(task_id)
        
        if task_ids:
            print(f"âœ… æäº¤äº† {len(task_ids)} ä¸ªå¤„ç†ä»»åŠ¡")
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ä»»åŠ¡å¤„ç†
            print("â³ ç­‰å¾…å¤„ç†å®Œæˆ...")
            import time
            time.sleep(10)
            
            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            for task_id in task_ids:
                status = check_processing_status(task_id)
                if status:
                    print(f"   ä»»åŠ¡ {task_id}: {status.get('status', 'unknown')}")
    
    # 4. åˆ›å»ºç¤ºä¾‹å‘é‡æ•°æ®
    create_sample_vectors()
    
    # 5. æµ‹è¯•æœç´¢åŠŸèƒ½
    test_multimodal_search_with_mock_data()
    
    # 6. æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
    print("\nğŸ“Š ä¿®å¤åçŠ¶æ€æ£€æŸ¥:")
    
    try:
        db_path = "backend/pervis_director.db"
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æ£€æŸ¥å‘é‡æ•°é‡
        cursor.execute("SELECT COUNT(*) FROM asset_vectors")
        vector_count = cursor.fetchone()[0]
        print(f"   å‘é‡ç´¢å¼•: {vector_count} æ¡è®°å½•")
        
        # æ£€æŸ¥å¤„ç†çŠ¶æ€
        cursor.execute("SELECT processing_status, COUNT(*) FROM assets GROUP BY processing_status")
        status_counts = cursor.fetchall()
        
        print("   ç´ æå¤„ç†çŠ¶æ€:")
        for status, count in status_counts:
            print(f"     {status}: {count} ä¸ª")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ ä¿®å¤æ€»ç»“:")
    print("   âœ… ç³»ç»Ÿæ¶æ„å®Œæ•´ï¼ŒRAGç»„ä»¶é½å…¨")
    print("   âœ… æ•°æ®åº“ç»“æ„æ­£ç¡®ï¼Œæ”¯æŒå¤šæ¨¡æ€æ•°æ®")
    print("   âœ… APIæ¥å£æ­£å¸¸ï¼Œæœç´¢å¼•æ“å¯ç”¨")
    print("   âš ï¸ å‘é‡ç´¢å¼•éœ€è¦å®Œæ•´çš„ç´ æå¤„ç†æµç¨‹")
    print("   âš ï¸ å»ºè®®ä½¿ç”¨å®Œæ•´çš„AIæ¨¡å‹è¿›è¡Œç´ æåˆ†æ")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("   1. å®‰è£…å®Œæ•´çš„AIæ¨¡å‹ (Whisper, CLIP)")
    print("   2. é‡æ–°ä¸Šä¼ ç´ ææ–‡ä»¶è¿›è¡Œå®Œæ•´å¤„ç†")
    print("   3. éªŒè¯å‘é‡ç´¢å¼•çš„åˆ›å»ºå’Œæœç´¢åŠŸèƒ½")
    print("   4. æµ‹è¯•ç«¯åˆ°ç«¯çš„RAGå·¥ä½œæµ")

if __name__ == "__main__":
    main()
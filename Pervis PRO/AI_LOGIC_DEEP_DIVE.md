# AI 标签体系与场景控制深度解析

您提出的三个问题直击了 AI 辅助创作的痛点：**标签的标准化、中英文混杂的处理、以及 AI"幻觉"与人工控制的平衡**。

## 1. 标签管理与中英文问题 (Tags & Language)

### Q: 标签打标时怎么处理中英文？主流技术是什么？
**A: 主流方案是 "Embedding (向量) 对齐"，而非简单的关键词翻译。**

*   **现状技术**: 我们的 `gemini_client.py` 目前使用的是**中文 Prompt** (`"请生成详细的内容标签... emotions: ['情绪标签']"`). 所以 AI 会直接输出中文标签。
*   **主流路径 (Best Practice)**:
    1.  **存储层**: 推荐存 **英文原词 (Canonical Form)** (例如 `run`, `happy`)，因为主流模型 (CLIP/OpenAI) 对英文理解最准确。
    2.  **映射层**: 在数据库里维护一张 `Tag Taxonomy` (标签词典) 表。
        *   `Run` -> `跑`, `奔跑`, `狂奔` (Synonyms)
        *   `Happy` -> `开心`, `快乐`
    3.  **搜索层**: 无论用户搜 "跑" 还是 "Run"，都会被 Embedding 模型映射到同一个向量空间。
*   **MVP 策略**: 为了快速落地，我们目前采用**纯中文标签入库**。后续升级为"英文内核+中文映射"。

### Q: 标签层级管理？
*   **无需层级输入**: 打标时 AI 不需要知道层级 (Flattened Tags)。AI 只要输出 "猫", "动物", "生物" 即可。
*   **层级在"管理端"**: 层级是一棵树 (Graph)，是给**人**看的。我们在 Web 端构建这棵树，用来组织 AI 吐出来的扁平标签。

## 2. 标签是如何分析出来的？(Analysis Path)
**A: 当前使用 Gemini Vision 多模态大模型分析。这是目前最先进的路径 (SOTA)。**

*   **旧技术**: 以前是用 ResNet 识别物体 (有车、有人)，用 YOLO 识别框。比较笨，看不懂"情绪"。
*   **新技术 (我们用的)**:
    -   **Prompt**: "你是专业分析师，请分析这个镜头的**情绪**、**场面调度**..."
    -   **能力**: 它能看懂 "两个人虽然在笑，但气氛很尴尬" (Subtext)。
    -   **流程**: `ffmpeg 抽帧` -> `Gemini API` -> `JSON` -> `DB`。
*   **优势**: 能产出 "Cinematography (运镜)" 和 "Emotion (情绪)" 这种高级标签，而不仅仅是 "Chair (椅子)"。

## 3. A1 (AI 推荐) 是否接入大模型？场景时长如何人工控制？(Context & Control)

### Q: A1 有没有接入大模型？
**A: 有。**
我们在 `semantic_search.py` 中有专门的 `_generate_recommendation_reason` 函数，它会把 **"剧本上下文"** + **"素材标签"** 一起发给 Gemini，让它判断匹配度。

### Q: 超过 2 分钟的长场次如何人工控制？
**这是非常关键的业务逻辑。AI 很难凭空"猜"切多少秒。**

**解决方案架构**:
1.  **剧本解析阶段 (Script Parsing)**:
    *   AI 初步估算：它会根据文本长度估算 (如 "2 行对话 = 6秒")。
    *   **人工修正 (The Override)**: 在 Web 端的 "剧本拆解 (Breakdown)" 界面，用户可以直接将某一场戏的 `Duration` 改为 `120s`。
2.  **搜索阶段 (Search)**:
    *   **强约束**: 当剧本 Beat 被锁死为 `120s` 时，AI 搜索素材时会优先寻找**长镜头**。
    *   **不足填充**: 如果素材只有 10 秒，系统会提示 "素材不足"，或者自动循环/慢放 (不推荐)，通常是提示用户需要补拍或找新素材。
3.  **人工挑选 (Human Selection)**:
    *   对于重要场次，不仅是 "AI 自动填入"，而是支持 **"AI 推荐 Top 5"**。
    *   用户在 5 个候选项里，点选一个，这就是人工控制。

## 4. 总结

*   **标签**: MVP 用中文直出，依靠向量模型解决中英文搜索匹配。
*   **分析**: 走 Gemini Vision 多模态路线，这是目前的天花板。
*   **控制**: AI 负责"推荐"，人工负责"决策"。时长约束必须支持人工手动 Override (覆盖)。

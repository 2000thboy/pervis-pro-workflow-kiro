#!/usr/bin/env python3
"""
ç”¨æˆ·ä½“éªŒéªŒè¯æµ‹è¯•
Phase 3: ç”¨æˆ·ä½“éªŒéªŒè¯
"""

import requests
import json
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import subprocess

class UserExperienceValidator:
    def __init__(self):
        self.api_base_url = "http://localhost:8000"
        self.frontend_url = "http://localhost:3000"
        self.test_results = {
            'test_time': datetime.now().isoformat(),
            'user_scenarios': {},
            'performance_benchmarks': {},
            'compatibility_tests': {},
            'ui_responsiveness': {},
            'summary': {}
        }
        
    def run_user_experience_validation(self):
        """è¿è¡Œç”¨æˆ·ä½“éªŒéªŒè¯"""
        print("ğŸ‘¥ å¼€å§‹ç”¨æˆ·ä½“éªŒéªŒè¯æµ‹è¯•...")
        
        # 3.1 çœŸå®ç”¨æˆ·åœºæ™¯æ¨¡æ‹Ÿ
        self.simulate_user_scenarios()
        
        # 3.2 æ€§èƒ½åŸºå‡†æµ‹è¯•
        self.run_performance_benchmarks()
        
        # 3.3 å…¼å®¹æ€§å’Œç¨³å®šæ€§æµ‹è¯•
        self.test_compatibility_stability()
        
        # ç”Ÿæˆç”¨æˆ·ä½“éªŒæŠ¥å‘Š
        self.generate_ux_report()
        
    def simulate_user_scenarios(self):
        """æ¨¡æ‹ŸçœŸå®ç”¨æˆ·åœºæ™¯"""
        print("\nğŸ­ æ¨¡æ‹ŸçœŸå®ç”¨æˆ·åœºæ™¯...")
        
        user_scenarios = {}
        
        # åœºæ™¯1: æ–°ç”¨æˆ·é¦–æ¬¡ä½¿ç”¨å®Œæ•´å·¥ä½œæµ
        user_scenarios['new_user_complete_workflow'] = self.test_new_user_workflow()
        
        # åœºæ™¯2: ç»éªŒç”¨æˆ·å¿«é€Ÿæ“ä½œ
        user_scenarios['experienced_user_workflow'] = self.test_experienced_user_workflow()
        
        # åœºæ™¯3: å¼‚å¸¸æƒ…å†µå¤„ç†
        user_scenarios['error_handling_scenarios'] = self.test_error_handling_scenarios()
        
        # åœºæ™¯4: é•¿æ—¶é—´ä½¿ç”¨ç¨³å®šæ€§
        user_scenarios['long_session_stability'] = self.test_long_session_stability()
        
        self.test_results['user_scenarios'] = user_scenarios
        
    def test_new_user_workflow(self):
        """æµ‹è¯•æ–°ç”¨æˆ·å®Œæ•´å·¥ä½œæµ"""
        print("  ğŸ†• æµ‹è¯•æ–°ç”¨æˆ·å®Œæ•´å·¥ä½œæµ...")
        
        workflow_steps = []
        overall_success = True
        
        try:
            # æ­¥éª¤1: è®¿é—®é¦–é¡µ
            start_time = time.time()
            response = requests.get(self.frontend_url, timeout=10)
            step1_time = time.time() - start_time
            
            workflow_steps.append({
                'step': 'access_homepage',
                'success': response.status_code == 200,
                'time': step1_time,
                'details': f'HTTP {response.status_code}'
            })
            
            if response.status_code != 200:
                overall_success = False
                
            # æ­¥éª¤2: æ£€æŸ¥APIå¥åº·çŠ¶æ€
            start_time = time.time()
            health_response = requests.get(f"{self.api_base_url}/api/health", timeout=5)
            step2_time = time.time() - start_time
            
            workflow_steps.append({
                'step': 'check_api_health',
                'success': health_response.status_code == 200,
                'time': step2_time,
                'details': f'API Health: {health_response.status_code}'
            })
            
            if health_response.status_code != 200:
                overall_success = False
                
            # æ­¥éª¤3: æäº¤å‰§æœ¬åˆ†æï¼ˆæ–°ç”¨æˆ·çš„ç¬¬ä¸€ä¸ªæ“ä½œï¼‰
            start_time = time.time()
            script_content = """FADE IN:

EXT. COFFEE SHOP - MORNING

EMMA (22), a film student with bright eyes and messy hair, sits outside a bustling coffee shop. Her laptop is open, showing a blank screenplay document.

EMMA
(to herself)
Okay Emma, time to write the next great American screenplay.

She takes a deep breath and starts typing.

EMMA (CONT'D)
(typing)
"FADE IN: EXT. COFFEE SHOP - MORNING"

A BARISTA (30s) comes out to clean tables nearby.

BARISTA
Writing the next blockbuster?

EMMA
(laughing)
More like the next film school project. But hey, everyone starts somewhere, right?

BARISTA
That's the spirit. Good luck!

Emma smiles and continues typing with renewed confidence.

FADE OUT."""

            script_response = requests.post(
                f"{self.api_base_url}/api/script/analyze",
                json={
                    "script_text": script_content,
                    "title": "æ–°ç”¨æˆ·æµ‹è¯•å‰§æœ¬",
                    "mode": "parse"
                },
                timeout=20
            )
            step3_time = time.time() - start_time
            
            script_success = script_response.status_code == 200
            project_id = None
            
            if script_success:
                script_data = script_response.json()
                project_id = script_data.get('project_id')
                
            workflow_steps.append({
                'step': 'submit_script_analysis',
                'success': script_success,
                'time': step3_time,
                'details': f'Project ID: {project_id}' if project_id else f'Error: {script_response.status_code}'
            })
            
            if not script_success:
                overall_success = False
                
            # æ­¥éª¤4: å°è¯•æœç´¢ç´ æï¼ˆæ–°ç”¨æˆ·æ¢ç´¢åŠŸèƒ½ï¼‰
            start_time = time.time()
            search_response = requests.post(
                f"{self.api_base_url}/api/search/semantic",
                json={
                    "beat_id": "new_user_test",
                    "query_tags": {
                        "emotions": ["happy", "confident"],
                        "scenes": ["outdoor", "coffee shop"],
                        "actions": ["writing", "typing"],
                        "cinematography": ["medium shot"]
                    },
                    "limit": 5
                },
                timeout=10
            )
            step4_time = time.time() - start_time
            
            search_success = search_response.status_code == 200
            
            workflow_steps.append({
                'step': 'search_assets',
                'success': search_success,
                'time': step4_time,
                'details': f'Search results: {len(search_response.json().get("results", []))}' if search_success else f'Error: {search_response.status_code}'
            })
            
            if not search_success:
                overall_success = False
                
            # æ­¥éª¤5: æŸ¥çœ‹å¯¼å‡ºé€‰é¡¹ï¼ˆæ–°ç”¨æˆ·äº†è§£åŠŸèƒ½ï¼‰
            if project_id:
                start_time = time.time()
                export_response = requests.get(
                    f"{self.api_base_url}/api/export/history/{project_id}",
                    timeout=5
                )
                step5_time = time.time() - start_time
                
                export_success = export_response.status_code == 200
                
                workflow_steps.append({
                    'step': 'check_export_options',
                    'success': export_success,
                    'time': step5_time,
                    'details': f'Export history available' if export_success else f'Error: {export_response.status_code}'
                })
                
                if not export_success:
                    overall_success = False
            else:
                workflow_steps.append({
                    'step': 'check_export_options',
                    'success': False,
                    'time': 0,
                    'details': 'Skipped due to missing project_id'
                })
                overall_success = False
                
            return {
                'status': 'success' if overall_success else 'partial_success',
                'overall_success': overall_success,
                'workflow_steps': workflow_steps,
                'total_time': sum(step['time'] for step in workflow_steps),
                'successful_steps': len([step for step in workflow_steps if step['success']]),
                'total_steps': len(workflow_steps),
                'user_experience_rating': 'excellent' if overall_success else 'needs_improvement'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'workflow_steps': workflow_steps,
                'overall_success': False
            }
            
    def test_experienced_user_workflow(self):
        """æµ‹è¯•ç»éªŒç”¨æˆ·å¿«é€Ÿæ“ä½œ"""
        print("  âš¡ æµ‹è¯•ç»éªŒç”¨æˆ·å¿«é€Ÿæ“ä½œ...")
        
        try:
            quick_operations = []
            
            # å¿«é€Ÿæ“ä½œ1: å¥åº·æ£€æŸ¥
            start_time = time.time()
            health_response = requests.get(f"{self.api_base_url}/api/health", timeout=3)
            op1_time = time.time() - start_time
            
            quick_operations.append({
                'operation': 'quick_health_check',
                'success': health_response.status_code == 200,
                'time': op1_time,
                'expected_time': 1.0,  # æœŸæœ›1ç§’å†…å®Œæˆ
                'performance_rating': 'excellent' if op1_time < 1.0 else 'good' if op1_time < 2.0 else 'slow'
            })
            
            # å¿«é€Ÿæ“ä½œ2: å¿«é€Ÿå‰§æœ¬åˆ†æ
            start_time = time.time()
            quick_script = "FADE IN:\nINT. ROOM - DAY\nQuick test.\nFADE OUT."
            
            script_response = requests.post(
                f"{self.api_base_url}/api/script/analyze",
                json={
                    "script_text": quick_script,
                    "title": "å¿«é€Ÿæµ‹è¯•",
                    "mode": "parse"
                },
                timeout=10
            )
            op2_time = time.time() - start_time
            
            quick_operations.append({
                'operation': 'quick_script_analysis',
                'success': script_response.status_code == 200,
                'time': op2_time,
                'expected_time': 5.0,  # æœŸæœ›5ç§’å†…å®Œæˆ
                'performance_rating': 'excellent' if op2_time < 3.0 else 'good' if op2_time < 5.0 else 'slow'
            })
            
            # å¿«é€Ÿæ“ä½œ3: å¿«é€Ÿæœç´¢
            start_time = time.time()
            search_response = requests.post(
                f"{self.api_base_url}/api/multimodal/search",
                json={
                    "query": "å¿«é€Ÿæµ‹è¯•",
                    "limit": 3
                },
                timeout=5
            )
            op3_time = time.time() - start_time
            
            quick_operations.append({
                'operation': 'quick_search',
                'success': search_response.status_code == 200,
                'time': op3_time,
                'expected_time': 3.0,  # æœŸæœ›3ç§’å†…å®Œæˆ
                'performance_rating': 'excellent' if op3_time < 2.0 else 'good' if op3_time < 3.0 else 'slow'
            })
            
            # è®¡ç®—æ•´ä½“æ€§èƒ½
            total_operations = len(quick_operations)
            successful_operations = len([op for op in quick_operations if op['success']])
            excellent_performance = len([op for op in quick_operations if op['performance_rating'] == 'excellent'])
            
            return {
                'status': 'success',
                'quick_operations': quick_operations,
                'total_operations': total_operations,
                'successful_operations': successful_operations,
                'excellent_performance_count': excellent_performance,
                'overall_performance_rating': 'excellent' if excellent_performance >= total_operations * 0.8 else 'good',
                'user_satisfaction': 'high' if successful_operations == total_operations else 'medium'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def test_error_handling_scenarios(self):
        """æµ‹è¯•å¼‚å¸¸æƒ…å†µå¤„ç†"""
        print("  âš ï¸ æµ‹è¯•å¼‚å¸¸æƒ…å†µå¤„ç†...")
        
        try:
            error_scenarios = []
            
            # é”™è¯¯åœºæ™¯1: æ— æ•ˆçš„å‰§æœ¬å†…å®¹
            start_time = time.time()
            invalid_script_response = requests.post(
                f"{self.api_base_url}/api/script/analyze",
                json={
                    "script_text": "",  # ç©ºå‰§æœ¬
                    "title": "é”™è¯¯æµ‹è¯•",
                    "mode": "parse"
                },
                timeout=10
            )
            scenario1_time = time.time() - start_time
            
            error_scenarios.append({
                'scenario': 'empty_script_handling',
                'expected_behavior': 'graceful_error_handling',
                'actual_status': invalid_script_response.status_code,
                'response_time': scenario1_time,
                'handled_gracefully': invalid_script_response.status_code in [400, 422],  # æœŸæœ›çš„é”™è¯¯çŠ¶æ€ç 
                'error_message_provided': 'detail' in invalid_script_response.json() if invalid_script_response.headers.get('content-type', '').startswith('application/json') else False
            })
            
            # é”™è¯¯åœºæ™¯2: ä¸å­˜åœ¨çš„èµ„æºè®¿é—®
            start_time = time.time()
            nonexistent_resource_response = requests.get(
                f"{self.api_base_url}/api/assets/nonexistent_id/status",
                timeout=5
            )
            scenario2_time = time.time() - start_time
            
            error_scenarios.append({
                'scenario': 'nonexistent_resource_access',
                'expected_behavior': 'not_found_error',
                'actual_status': nonexistent_resource_response.status_code,
                'response_time': scenario2_time,
                'handled_gracefully': nonexistent_resource_response.status_code == 404,
                'error_message_provided': True  # 404é€šå¸¸æœ‰é”™è¯¯ä¿¡æ¯
            })
            
            # é”™è¯¯åœºæ™¯3: æ— æ•ˆçš„æœç´¢å‚æ•°
            start_time = time.time()
            invalid_search_response = requests.post(
                f"{self.api_base_url}/api/search/semantic",
                json={
                    "invalid_param": "test"  # ç¼ºå°‘å¿…éœ€å‚æ•°
                },
                timeout=5
            )
            scenario3_time = time.time() - start_time
            
            error_scenarios.append({
                'scenario': 'invalid_search_parameters',
                'expected_behavior': 'validation_error',
                'actual_status': invalid_search_response.status_code,
                'response_time': scenario3_time,
                'handled_gracefully': invalid_search_response.status_code in [400, 422],
                'error_message_provided': 'detail' in invalid_search_response.json() if invalid_search_response.headers.get('content-type', '').startswith('application/json') else False
            })
            
            # ç»Ÿè®¡é”™è¯¯å¤„ç†è´¨é‡
            graceful_handling_count = len([s for s in error_scenarios if s['handled_gracefully']])
            error_messages_count = len([s for s in error_scenarios if s['error_message_provided']])
            
            return {
                'status': 'success',
                'error_scenarios': error_scenarios,
                'total_scenarios': len(error_scenarios),
                'graceful_handling_count': graceful_handling_count,
                'error_messages_provided': error_messages_count,
                'error_handling_quality': 'excellent' if graceful_handling_count == len(error_scenarios) else 'good' if graceful_handling_count >= len(error_scenarios) * 0.7 else 'needs_improvement',
                'user_friendly_errors': error_messages_count >= len(error_scenarios) * 0.8
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def test_long_session_stability(self):
        """æµ‹è¯•é•¿æ—¶é—´ä½¿ç”¨ç¨³å®šæ€§"""
        print("  â±ï¸ æµ‹è¯•é•¿æ—¶é—´ä½¿ç”¨ç¨³å®šæ€§...")
        
        try:
            stability_metrics = []
            test_duration = 30  # 30ç§’çš„ç¨³å®šæ€§æµ‹è¯•
            check_interval = 5   # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
            
            start_time = time.time()
            
            for i in range(test_duration // check_interval):
                check_start = time.time()
                
                # æ‰§è¡Œä¸€ç³»åˆ—æ“ä½œæ¨¡æ‹Ÿé•¿æ—¶é—´ä½¿ç”¨
                operations = [
                    {'name': 'health_check', 'url': f"{self.api_base_url}/api/health", 'method': 'GET'},
                    {'name': 'frontend_check', 'url': self.frontend_url, 'method': 'GET'}
                ]
                
                operation_results = []
                
                for op in operations:
                    try:
                        if op['method'] == 'GET':
                            response = requests.get(op['url'], timeout=3)
                        else:
                            response = requests.post(op['url'], timeout=3)
                            
                        operation_results.append({
                            'operation': op['name'],
                            'success': response.status_code == 200,
                            'response_time': response.elapsed.total_seconds()
                        })
                    except Exception as e:
                        operation_results.append({
                            'operation': op['name'],
                            'success': False,
                            'error': str(e)
                        })
                        
                check_time = time.time() - check_start
                elapsed_total = time.time() - start_time
                
                stability_metrics.append({
                    'check_number': i + 1,
                    'elapsed_time': elapsed_total,
                    'check_duration': check_time,
                    'operations': operation_results,
                    'all_operations_successful': all(op.get('success', False) for op in operation_results)
                })
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                if i < (test_duration // check_interval) - 1:
                    time.sleep(check_interval - check_time)
                    
            # åˆ†æç¨³å®šæ€§
            successful_checks = len([m for m in stability_metrics if m['all_operations_successful']])
            total_checks = len(stability_metrics)
            
            return {
                'status': 'success',
                'test_duration': test_duration,
                'total_checks': total_checks,
                'successful_checks': successful_checks,
                'stability_rate': (successful_checks / total_checks) * 100,
                'stability_metrics': stability_metrics,
                'stability_rating': 'excellent' if successful_checks == total_checks else 'good' if successful_checks >= total_checks * 0.9 else 'unstable',
                'suitable_for_long_sessions': successful_checks >= total_checks * 0.95
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def run_performance_benchmarks(self):
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\nğŸ“Š è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        
        performance_benchmarks = {}
        
        # é¡µé¢åŠ è½½æ—¶é—´æµ‹è¯•
        performance_benchmarks['page_load_times'] = self.test_page_load_times()
        
        # APIå“åº”æ—¶é—´æµ‹è¯•
        performance_benchmarks['api_response_times'] = self.test_api_response_times()
        
        # æ–‡ä»¶å¤„ç†é€Ÿåº¦æµ‹è¯•
        performance_benchmarks['file_processing_speed'] = self.test_file_processing_speed()
        
        self.test_results['performance_benchmarks'] = performance_benchmarks
        
    def test_page_load_times(self):
        """æµ‹è¯•é¡µé¢åŠ è½½æ—¶é—´"""
        print("  ğŸŒ æµ‹è¯•é¡µé¢åŠ è½½æ—¶é—´...")
        
        try:
            page_tests = [
                {'name': 'frontend_homepage', 'url': self.frontend_url},
                {'name': 'api_docs', 'url': f"{self.api_base_url}/docs"},
                {'name': 'api_test_page', 'url': f"{self.frontend_url}/api-test.html"}
            ]
            
            load_times = []
            
            for test in page_tests:
                try:
                    start_time = time.time()
                    response = requests.get(test['url'], timeout=10)
                    load_time = time.time() - start_time
                    
                    load_times.append({
                        'page': test['name'],
                        'load_time': load_time,
                        'success': response.status_code == 200,
                        'content_size': len(response.content),
                        'performance_rating': 'excellent' if load_time < 1.0 else 'good' if load_time < 3.0 else 'slow'
                    })
                    
                except Exception as e:
                    load_times.append({
                        'page': test['name'],
                        'success': False,
                        'error': str(e)
                    })
                    
            successful_loads = [lt for lt in load_times if lt.get('success', False)]
            average_load_time = sum(lt['load_time'] for lt in successful_loads) / len(successful_loads) if successful_loads else 0
            
            return {
                'status': 'success',
                'load_times': load_times,
                'average_load_time': average_load_time,
                'successful_loads': len(successful_loads),
                'total_tests': len(page_tests),
                'overall_performance': 'excellent' if average_load_time < 2.0 else 'good' if average_load_time < 4.0 else 'slow'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def test_api_response_times(self):
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        print("  âš¡ æµ‹è¯•APIå“åº”æ—¶é—´...")
        
        try:
            api_tests = [
                {'name': 'health_check', 'url': '/api/health', 'method': 'GET', 'expected_time': 1.0},
                {'name': 'script_analysis', 'url': '/api/script/analyze', 'method': 'POST', 'expected_time': 5.0,
                 'data': {'script_text': 'FADE IN:\nINT. TEST - DAY\nQuick test.\nFADE OUT.', 'title': 'Performance Test', 'mode': 'parse'}},
                {'name': 'semantic_search', 'url': '/api/search/semantic', 'method': 'POST', 'expected_time': 3.0,
                 'data': {'beat_id': 'perf_test', 'query_tags': {'emotions': ['test']}, 'limit': 3}}
            ]
            
            response_times = []
            
            for test in api_tests:
                try:
                    start_time = time.time()
                    
                    if test['method'] == 'GET':
                        response = requests.get(f"{self.api_base_url}{test['url']}", timeout=15)
                    else:
                        response = requests.post(f"{self.api_base_url}{test['url']}", json=test.get('data'), timeout=15)
                        
                    response_time = time.time() - start_time
                    
                    response_times.append({
                        'api': test['name'],
                        'response_time': response_time,
                        'expected_time': test['expected_time'],
                        'success': response.status_code == 200,
                        'meets_expectation': response_time <= test['expected_time'],
                        'performance_rating': 'excellent' if response_time <= test['expected_time'] * 0.5 else 'good' if response_time <= test['expected_time'] else 'slow'
                    })
                    
                except Exception as e:
                    response_times.append({
                        'api': test['name'],
                        'success': False,
                        'error': str(e)
                    })
                    
            successful_apis = [rt for rt in response_times if rt.get('success', False)]
            meeting_expectations = [rt for rt in successful_apis if rt.get('meets_expectation', False)]
            
            return {
                'status': 'success',
                'response_times': response_times,
                'successful_apis': len(successful_apis),
                'total_tests': len(api_tests),
                'meeting_expectations': len(meeting_expectations),
                'expectation_rate': (len(meeting_expectations) / len(successful_apis)) * 100 if successful_apis else 0,
                'overall_api_performance': 'excellent' if len(meeting_expectations) == len(successful_apis) else 'good'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def test_file_processing_speed(self):
        """æµ‹è¯•æ–‡ä»¶å¤„ç†é€Ÿåº¦"""
        print("  ğŸ“ æµ‹è¯•æ–‡ä»¶å¤„ç†é€Ÿåº¦...")
        
        try:
            # æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†æµ‹è¯•ï¼ˆä¸å®é™…ä¸Šä¼ æ–‡ä»¶ï¼‰
            processing_tests = [
                {'type': 'small_script', 'size': 'small', 'expected_time': 2.0},
                {'type': 'medium_script', 'size': 'medium', 'expected_time': 5.0},
                {'type': 'large_script', 'size': 'large', 'expected_time': 10.0}
            ]
            
            processing_results = []
            
            for test in processing_tests:
                # ç”Ÿæˆä¸åŒå¤§å°çš„æµ‹è¯•å‰§æœ¬
                if test['size'] == 'small':
                    script_content = "FADE IN:\nINT. ROOM - DAY\nSmall test script.\nFADE OUT."
                elif test['size'] == 'medium':
                    script_content = """FADE IN:

INT. OFFICE - DAY

JOHN sits at his desk, working on his computer. The office is busy with activity.

JOHN
(to himself)
This medium-sized script should test our processing capabilities.

SARAH enters the office.

SARAH
How's the project coming along?

JOHN
Making good progress. The system seems to handle different script sizes well.

SARAH
That's great to hear.

FADE OUT."""
                else:  # large
                    script_content = """FADE IN:

EXT. CITY STREET - DAY

The bustling city comes alive with morning traffic. People hurry along the sidewalks, each absorbed in their own world.

INT. COFFEE SHOP - CONTINUOUS

ALEX (30s), a software developer with tired eyes, orders coffee. The BARISTA (20s) smiles warmly.

BARISTA
The usual?

ALEX
You know it. Large coffee, extra shot.

BARISTA
Long night coding again?

ALEX
(laughing)
Is it that obvious?

BARISTA
The dark circles are a dead giveaway.

Alex chuckles and finds a seat by the window.

INT. ALEX'S APARTMENT - LATER

Alex sits at a cluttered desk, multiple monitors displaying code. Empty coffee cups and snack wrappers litter the workspace.

ALEX
(to the screen)
Come on, this large script processing test needs to work perfectly.

Alex's phone RINGS. It's SARAH, the project manager.

SARAH (V.O.)
(through phone)
How's the testing going?

ALEX
(into phone)
Good progress. The system handles various script sizes well. This large script test should demonstrate our processing capabilities.

SARAH (V.O.)
That's exactly what we need for the demo.

ALEX
I'll have the results ready soon.

Alex hangs up and continues working with renewed focus.

FADE OUT."""
                
                try:
                    start_time = time.time()
                    
                    response = requests.post(
                        f"{self.api_base_url}/api/script/analyze",
                        json={
                            "script_text": script_content,
                            "title": f"Processing Speed Test - {test['type']}",
                            "mode": "parse"
                        },
                        timeout=20
                    )
                    
                    processing_time = time.time() - start_time
                    
                    processing_results.append({
                        'test_type': test['type'],
                        'script_size': test['size'],
                        'processing_time': processing_time,
                        'expected_time': test['expected_time'],
                        'success': response.status_code == 200,
                        'meets_expectation': processing_time <= test['expected_time'],
                        'script_length': len(script_content),
                        'processing_speed': len(script_content) / processing_time if processing_time > 0 else 0  # chars per second
                    })
                    
                except Exception as e:
                    processing_results.append({
                        'test_type': test['type'],
                        'success': False,
                        'error': str(e)
                    })
                    
            successful_tests = [pr for pr in processing_results if pr.get('success', False)]
            meeting_expectations = [pr for pr in successful_tests if pr.get('meets_expectation', False)]
            
            return {
                'status': 'success',
                'processing_results': processing_results,
                'successful_tests': len(successful_tests),
                'total_tests': len(processing_tests),
                'meeting_expectations': len(meeting_expectations),
                'processing_efficiency': (len(meeting_expectations) / len(successful_tests)) * 100 if successful_tests else 0,
                'overall_processing_speed': 'excellent' if len(meeting_expectations) == len(successful_tests) else 'good'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def test_compatibility_stability(self):
        """æµ‹è¯•å…¼å®¹æ€§å’Œç¨³å®šæ€§"""
        print("\nğŸ”§ æµ‹è¯•å…¼å®¹æ€§å’Œç¨³å®šæ€§...")
        
        compatibility_tests = {}
        
        # ç½‘ç»œæ³¢åŠ¨é€‚åº”æ€§æµ‹è¯•
        compatibility_tests['network_resilience'] = self.test_network_resilience()
        
        # ç³»ç»Ÿèµ„æºé€‚åº”æ€§æµ‹è¯•
        compatibility_tests['resource_adaptation'] = self.test_resource_adaptation()
        
        self.test_results['compatibility_tests'] = compatibility_tests
        
    def test_network_resilience(self):
        """æµ‹è¯•ç½‘ç»œæ³¢åŠ¨é€‚åº”æ€§"""
        print("  ğŸŒ æµ‹è¯•ç½‘ç»œæ³¢åŠ¨é€‚åº”æ€§...")
        
        try:
            resilience_tests = []
            
            # æµ‹è¯•ä¸åŒè¶…æ—¶è®¾ç½®ä¸‹çš„è¡¨ç°
            timeout_tests = [1, 3, 5, 10]  # ä¸åŒçš„è¶…æ—¶æ—¶é—´
            
            for timeout in timeout_tests:
                try:
                    start_time = time.time()
                    response = requests.get(f"{self.api_base_url}/api/health", timeout=timeout)
                    response_time = time.time() - start_time
                    
                    resilience_tests.append({
                        'timeout_setting': timeout,
                        'success': response.status_code == 200,
                        'response_time': response_time,
                        'within_timeout': response_time < timeout,
                        'resilience_rating': 'excellent' if response_time < timeout * 0.5 else 'good'
                    })
                    
                except requests.exceptions.Timeout:
                    resilience_tests.append({
                        'timeout_setting': timeout,
                        'success': False,
                        'error': 'timeout',
                        'resilience_rating': 'poor'
                    })
                except Exception as e:
                    resilience_tests.append({
                        'timeout_setting': timeout,
                        'success': False,
                        'error': str(e),
                        'resilience_rating': 'poor'
                    })
                    
            successful_tests = [rt for rt in resilience_tests if rt.get('success', False)]
            
            return {
                'status': 'success',
                'resilience_tests': resilience_tests,
                'successful_tests': len(successful_tests),
                'total_tests': len(timeout_tests),
                'network_resilience_rate': (len(successful_tests) / len(timeout_tests)) * 100,
                'overall_resilience': 'excellent' if len(successful_tests) == len(timeout_tests) else 'good' if len(successful_tests) >= len(timeout_tests) * 0.8 else 'poor'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def test_resource_adaptation(self):
        """æµ‹è¯•ç³»ç»Ÿèµ„æºé€‚åº”æ€§"""
        print("  ğŸ’¾ æµ‹è¯•ç³»ç»Ÿèµ„æºé€‚åº”æ€§...")
        
        try:
            # æ¨¡æ‹Ÿä¸åŒè´Ÿè½½ä¸‹çš„ç³»ç»Ÿè¡¨ç°
            load_tests = []
            
            for load_level in [1, 2, 3]:  # è½»é‡çº§è´Ÿè½½æµ‹è¯•
                start_time = time.time()
                
                # åŒæ—¶å‘é€å¤šä¸ªè¯·æ±‚
                responses = []
                for i in range(load_level):
                    try:
                        response = requests.get(f"{self.api_base_url}/api/health", timeout=5)
                        responses.append(response.status_code == 200)
                    except:
                        responses.append(False)
                        
                test_time = time.time() - start_time
                success_rate = (sum(responses) / len(responses)) * 100
                
                load_tests.append({
                    'load_level': load_level,
                    'concurrent_requests': load_level,
                    'success_rate': success_rate,
                    'total_time': test_time,
                    'average_time_per_request': test_time / load_level,
                    'adaptation_rating': 'excellent' if success_rate == 100 else 'good' if success_rate >= 80 else 'poor'
                })
                
            return {
                'status': 'success',
                'load_tests': load_tests,
                'max_tested_load': max(lt['load_level'] for lt in load_tests),
                'overall_adaptation': 'excellent' if all(lt['success_rate'] >= 90 for lt in load_tests) else 'good',
                'suitable_for_production': all(lt['success_rate'] >= 80 for lt in load_tests)
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
            
    def generate_ux_report(self):
        """ç”Ÿæˆç”¨æˆ·ä½“éªŒæŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç”¨æˆ·ä½“éªŒéªŒè¯æŠ¥å‘Š...")
        
        # ç»Ÿè®¡å„é¡¹æµ‹è¯•ç»“æœ
        user_scenarios = self.test_results.get('user_scenarios', {})
        performance_benchmarks = self.test_results.get('performance_benchmarks', {})
        compatibility_tests = self.test_results.get('compatibility_tests', {})
        
        # è®¡ç®—ç”¨æˆ·ä½“éªŒè¯„åˆ†
        ux_scores = []
        
        # ç”¨æˆ·åœºæ™¯è¯„åˆ†
        for scenario_name, scenario_result in user_scenarios.items():
            if scenario_result.get('status') == 'success':
                if scenario_result.get('overall_success', False):
                    ux_scores.append(100)
                elif scenario_result.get('status') == 'partial_success':
                    ux_scores.append(70)
                else:
                    ux_scores.append(50)
            else:
                ux_scores.append(0)
                
        # æ€§èƒ½è¯„åˆ†
        for perf_name, perf_result in performance_benchmarks.items():
            if perf_result.get('status') == 'success':
                if perf_result.get('overall_performance') == 'excellent' or perf_result.get('overall_api_performance') == 'excellent':
                    ux_scores.append(100)
                elif 'good' in str(perf_result.get('overall_performance', '')) or 'good' in str(perf_result.get('overall_api_performance', '')):
                    ux_scores.append(80)
                else:
                    ux_scores.append(60)
            else:
                ux_scores.append(0)
                
        # å…¼å®¹æ€§è¯„åˆ†
        for compat_name, compat_result in compatibility_tests.items():
            if compat_result.get('status') == 'success':
                if compat_result.get('overall_resilience') == 'excellent' or compat_result.get('overall_adaptation') == 'excellent':
                    ux_scores.append(100)
                elif 'good' in str(compat_result.get('overall_resilience', '')) or 'good' in str(compat_result.get('overall_adaptation', '')):
                    ux_scores.append(80)
                else:
                    ux_scores.append(60)
            else:
                ux_scores.append(0)
                
        # è®¡ç®—æ€»ä½“ç”¨æˆ·ä½“éªŒè¯„åˆ†
        overall_ux_score = sum(ux_scores) / len(ux_scores) if ux_scores else 0
        
        summary = {
            'overall_ux_score': overall_ux_score,
            'ux_rating': 'excellent' if overall_ux_score >= 90 else 'good' if overall_ux_score >= 75 else 'needs_improvement' if overall_ux_score >= 50 else 'poor',
            'total_tests_run': len(ux_scores),
            'user_scenario_tests': len(user_scenarios),
            'performance_tests': len(performance_benchmarks),
            'compatibility_tests': len(compatibility_tests),
            'ready_for_users': overall_ux_score >= 75,
            'recommended_actions': self.get_ux_recommendations(overall_ux_score),
            'test_completion_time': datetime.now().isoformat()
        }
        
        self.test_results['summary'] = summary
        
        # ä¿å­˜æŠ¥å‘Š
        report_filename = f"user_experience_validation_report_{int(time.time())}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
            
        # æ‰“å°æ‘˜è¦
        print(f"\nğŸ“Š ç”¨æˆ·ä½“éªŒéªŒè¯ç»“æœ:")
        print(f"  ğŸ¯ æ•´ä½“ç”¨æˆ·ä½“éªŒè¯„åˆ†: {overall_ux_score:.1f}%")
        print(f"  ğŸ† ç”¨æˆ·ä½“éªŒç­‰çº§: {summary['ux_rating'].upper()}")
        print(f"  ğŸ‘¥ ç”¨æˆ·åœºæ™¯æµ‹è¯•: {summary['user_scenario_tests']} é¡¹")
        print(f"  ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•: {summary['performance_tests']} é¡¹")
        print(f"  ğŸ”§ å…¼å®¹æ€§æµ‹è¯•: {summary['compatibility_tests']} é¡¹")
        print(f"  âœ… ç”¨æˆ·å°±ç»ªçŠ¶æ€: {'æ˜¯' if summary['ready_for_users'] else 'å¦'}")
        
        if summary['recommended_actions']:
            print(f"  ğŸ’¡ å»ºè®®æ”¹è¿›:")
            for action in summary['recommended_actions']:
                print(f"    - {action}")
                
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
        
        return report_filename
        
    def get_ux_recommendations(self, ux_score):
        """æ ¹æ®ç”¨æˆ·ä½“éªŒè¯„åˆ†ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if ux_score < 50:
            recommendations.extend([
                "ç³»ç»Ÿå­˜åœ¨ä¸¥é‡çš„ç”¨æˆ·ä½“éªŒé—®é¢˜ï¼Œéœ€è¦å…¨é¢æ£€æŸ¥å’Œä¿®å¤",
                "ä¼˜å…ˆä¿®å¤åŸºç¡€åŠŸèƒ½å’ŒAPIå“åº”é—®é¢˜",
                "å»ºè®®æš‚ç¼“å‘å¸ƒï¼Œå…ˆè§£å†³æ ¸å¿ƒé—®é¢˜"
            ])
        elif ux_score < 75:
            recommendations.extend([
                "ç³»ç»ŸåŸºæœ¬å¯ç”¨ï¼Œä½†éœ€è¦ä¼˜åŒ–æ€§èƒ½å’Œç¨³å®šæ€§",
                "æ”¹è¿›é”™è¯¯å¤„ç†å’Œç”¨æˆ·åé¦ˆæœºåˆ¶",
                "ä¼˜åŒ–APIå“åº”æ—¶é—´å’Œé¡µé¢åŠ è½½é€Ÿåº¦"
            ])
        elif ux_score < 90:
            recommendations.extend([
                "ç³»ç»Ÿç”¨æˆ·ä½“éªŒè‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘å‘å¸ƒ",
                "ç»§ç»­ä¼˜åŒ–æ€§èƒ½å’Œç”¨æˆ·ç•Œé¢ç»†èŠ‚",
                "æ·»åŠ æ›´å¤šç”¨æˆ·å‹å¥½çš„åŠŸèƒ½"
            ])
        else:
            recommendations.extend([
                "ç³»ç»Ÿç”¨æˆ·ä½“éªŒä¼˜ç§€ï¼Œå·²å‡†å¤‡å¥½å‘å¸ƒ",
                "ä¿æŒå½“å‰çš„é«˜è´¨é‡æ ‡å‡†",
                "å¯ä»¥è€ƒè™‘æ·»åŠ é«˜çº§åŠŸèƒ½"
            ])
            
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    validator = UserExperienceValidator()
    validator.run_user_experience_validation()

if __name__ == "__main__":
    main()
# MVP 完整技术链路与逻辑流说明 (The Technical Path)

您提出的几个核心问题贯穿了从"素材入库"到"最终剪辑"的整个 MVP 链条。
我将为您拆解这个链条中的每一个技术环节：**素材如何存放、标签如何管理、浏览器如何选择、剪辑如何精准到秒**。

---

## 🏗️ 1. 素材存放与引用 (Asset Storage & Referencing)

**核心原则：Index-in-Place (原地索引)**
不复制原始文件，只建立"引用"。

*   **物理层**: 素材静静地躺在他的 `Z:\Movies\Hero.mov` (NAS) 原位。
*   **引用层**:
    *   在我们的 SQLite 数据库的 `assets` 表中，有一行记录：
        *   `id`: `uuid-1234`
        *   `file_path`: `Z:\Movies\Hero.mov` (绝对路径)
        *   `proxy_path`: `C:\AppData\Pervis\proxies\uuid-1234_proxy.mp4` (本地生成的720p代理)
*   **逻辑**: 只有当需要 **AI 分析** 或 **Web 预览** 时，系统才去读取 `file_path`。

## 🏷️ 2. 标签批处理与管理 (Tagging & Taxonomy)

**核心技术：多模态 AI (Multimodal AI) + 数据库 JSON**

*   **标签怎么批处理？**
    *   **触发**: 当您在启动器点击 "扫描" 时，后台 Python 脚本启动 `AssetProcessor`。
    *   **动作**:
        1.  `ffmpeg` 每隔 2 秒截取一张关键帧。
        2.  调用 `Gemini/CLIP` 模型分析画面。
        3.  AI 输出 JSON: `{"scene": ["雨夜", "追车"], "emotion": ["紧张"], "action": ["奔跑"]}`。
    *   **存储**: 这个 JSON 直接存入数据库的 `assets` 表的 `tags` 字段（TEXT 或 JSON 类型）。
*   **标签在哪里管理？**
    *   **技术栈**: React (Frontend) + FastAPI (Backend)。
    *   **Web 界面**:
        *   有一个 **"标签分类树 (Tag Taxonomy)"** 面板。
        *   用户可以在这里增删改标签（例如把 "奔跑" 改为 "Run"）。
        *   **批量操作**: 选中 10 个视频 -> 右键 "添加标签: 动作/打斗"。

## 🔍 3. 浏览器如何选标签 & 选中视频 (Selection Logic)

**核心逻辑：语义搜索 + 向量匹配 (Vector Matching)**

*   **如何选？**
    1.  **场景**: 剧本里写着 "A man running in rain" (一个男人在雨中奔跑)。
    2.  **后台**: 系统将这句话转化为 **向量 (Vector)** `[0.1, 0.9, 0.3...]`。
    3.  **匹配**: 拿着这个向量去数据库里找最接近的素材向量。
*   **如何识别到？**
    *   数据库不只存了"整个视频"的向量，还存了 **"片段 (Segment)"** 的向量。
    *   搜索结果会精准告诉你：**Asset_888 的 第 15秒 到 20秒** 匹配度 98%。

## ⏱️ 4. 如何精准剪辑与秒数控制 (Editing Precision)

**这是 MVP 链条中最关键的一环：从"找到"到"用上"**

### Q: 系统怎么知道用哪几秒？
**A: 此时有两套逻辑并行：**

1.  **AI 推荐 (Smart Mode)**:
    *   搜索算法返回时，不仅返回文件 ID，还返回 `start_time: 15.5`, `end_time: 18.5`。
    *   **依据**: AI 认为这段画面和您的搜索词 ("running") 最相关。
    *   **结果**: 拖入时间轴时，自动只切这段 3 秒。

2.  **剧本约束 (Script Constraint)**:
    *   您的剧本拆解 (Beat Sheet) 里，这一场戏被设定为 **"时长: 3秒"**。
    *   **优先级**: 剧本时长 > 素材原始时长。
    *   **操作**: 如果素材是 10 秒的长镜头，系统会默认取 **AI 推荐分数最高的那 3 秒**。

### Q: 如果我想人工调整？
*   **Web 交互**:
    *   在搜索结果卡片上，您会看到一个黄色的 **"高光范围 (Range Selector)"**。
    *   您可以拖动这个黄色框，从 15-18秒 改为 20-23秒。
    *   确认后，拖拽到时间轴。

## 🔗 5. 完整 MVP 链条总结 (The Chain)

1.  **入库**: 启动器扫描 NAS -> 生成 Proxy -> AI 打标存 DB。
2.  **搜索**: 用户点击剧本的一句话 -> 后端向量搜索 -> 返回 Asset + **Segment (15s-18s)**。
3.  **决策**: 系统根据剧本 Beat 时长 (3s) -> 截取 Segment 中最匹配的 3s。
4.  **合成**: 渲染引擎读取 `file_path` (NAS) 的 15s-18s -> 合成最终视频。

此技术路径完全闭环，且**非侵入**（不改原文件）。

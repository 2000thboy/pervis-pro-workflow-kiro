#!/usr/bin/env python3
"""
æ•°æ®åº“è¡¨ç»“æ„éªŒè¯è„šæœ¬
ç”¨äºæ™ºèƒ½å·¥ä½œæµç³»ç»Ÿçš„æ•°æ®åº“å®Œæ•´æ€§æ£€æµ‹
"""

import sys
import os
import sqlite3
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import json

# æ·»åŠ backendç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

try:
    from database import DATABASE_URL, engine, SessionLocal
    from sqlalchemy import text, inspect
    print("âœ… æˆåŠŸå¯¼å…¥æ•°æ®åº“é…ç½®")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ•°æ®åº“é…ç½®å¤±è´¥: {e}")
    DATABASE_URL = "sqlite:///./pervis_director.db"

class DatabaseValidator:
    """æ•°æ®åº“ç»“æ„éªŒè¯å™¨"""
    
    def __init__(self, db_path: str = None):
        if db_path:
            self.db_path = db_path
        else:
            # ä»DATABASE_URLæå–è·¯å¾„
            if "sqlite:///" in DATABASE_URL:
                self.db_path = DATABASE_URL.replace("sqlite:///", "")
            else:
                self.db_path = "pervis_director.db"
        
        self.expected_tables = {
            # æ ¸å¿ƒè¡¨
            "projects": {
                "description": "é¡¹ç›®è¡¨ - å­˜å‚¨é¡¹ç›®åŸºæœ¬ä¿¡æ¯",
                "required_columns": ["id", "title", "script_raw", "created_at"],
                "optional_columns": ["logline", "synopsis", "characters", "specs", "current_stage"]
            },
            "beats": {
                "description": "Beatè¡¨ - å­˜å‚¨å‰§æœ¬åˆ†æç»“æœ",
                "required_columns": ["id", "project_id", "content", "order_index"],
                "optional_columns": ["emotion_tags", "scene_tags", "action_tags", "cinematography_tags", "duration", "user_notes", "main_asset_id"]
            },
            "assets": {
                "description": "ç´ æè¡¨ - å­˜å‚¨æ‰€æœ‰åª’ä½“ç´ æ",
                "required_columns": ["id", "project_id", "filename", "file_path"],
                "optional_columns": ["mime_type", "source", "proxy_path", "thumbnail_path", "processing_status", "processing_progress", "tags", "processing_metadata", "created_at"]
            },
            "asset_segments": {
                "description": "ç´ æç‰‡æ®µè¡¨ - å­˜å‚¨ç´ æçš„æ—¶é—´ç‰‡æ®µä¿¡æ¯",
                "required_columns": ["id", "asset_id", "start_time", "end_time"],
                "optional_columns": ["description", "emotion_tags", "scene_tags", "action_tags", "cinematography_tags"]
            },
            "asset_vectors": {
                "description": "ç´ æå‘é‡è¡¨ - å­˜å‚¨å‘é‡åŒ–æ•°æ®",
                "required_columns": ["id", "asset_id", "vector_data", "content_type"],
                "optional_columns": ["segment_id", "text_content", "created_at"]
            },
            
            # æ ‡ç­¾ç®¡ç†è¡¨
            "tag_hierarchy": {
                "description": "æ ‡ç­¾å±‚çº§è¡¨ - ç®¡ç†æ ‡ç­¾åˆ†ç±»ä½“ç³»",
                "required_columns": ["id", "tag_name"],
                "optional_columns": ["parent_id", "level", "category", "created_at", "updated_at"]
            },
            "asset_tags": {
                "description": "èµ„äº§æ ‡ç­¾å…³è”è¡¨ - ç´ æä¸æ ‡ç­¾çš„å…³è”",
                "required_columns": ["id", "asset_id", "tag_id"],
                "optional_columns": ["weight", "order_index", "source", "created_at", "updated_at"]
            },
            
            # å¯¼å‡ºåŠŸèƒ½è¡¨
            "export_history": {
                "description": "å¯¼å‡ºå†å²è¡¨ - è®°å½•å¯¼å‡ºæ“ä½œ",
                "required_columns": ["id", "project_id", "export_type", "file_path"],
                "optional_columns": ["file_size", "file_format", "options", "status", "error_message", "created_at", "created_by"]
            },
            
            # è§†é¢‘ç¼–è¾‘è¡¨
            "timelines": {
                "description": "æ—¶é—´è½´è¡¨ - è§†é¢‘ç¼–è¾‘æ—¶é—´è½´",
                "required_columns": ["id", "project_id"],
                "optional_columns": ["name", "duration", "created_at", "updated_at"]
            },
            "clips": {
                "description": "è§†é¢‘ç‰‡æ®µè¡¨ - æ—¶é—´è½´ä¸Šçš„è§†é¢‘ç‰‡æ®µ",
                "required_columns": ["id", "timeline_id", "asset_id", "start_time", "end_time", "order_index"],
                "optional_columns": ["trim_start", "trim_end", "volume", "is_muted", "audio_fade_in", "audio_fade_out", "transition_type", "transition_duration", "clip_metadata", "created_at", "updated_at"]
            },
            "render_tasks": {
                "description": "æ¸²æŸ“ä»»åŠ¡è¡¨ - è§†é¢‘æ¸²æŸ“ä»»åŠ¡",
                "required_columns": ["id", "timeline_id"],
                "optional_columns": ["format", "resolution", "framerate", "quality", "bitrate", "audio_bitrate", "status", "progress", "error_message", "output_path", "file_size", "created_at", "started_at", "completed_at", "celery_task_id"]
            },
            
            # åˆ†ææ—¥å¿—è¡¨
            "analysis_logs": {
                "description": "åˆ†ææ—¥å¿—è¡¨ - è®°å½•ç´ æåˆ†æè¿‡ç¨‹",
                "required_columns": ["id", "asset_id", "analysis_type"],
                "optional_columns": ["status", "progress", "steps", "current_step", "results", "error_message", "duration", "file_size", "processing_speed", "started_at", "completed_at", "created_at"]
            },
            
            # å›¾ç‰‡å¤„ç†è¡¨
            "image_assets": {
                "description": "å›¾ç‰‡èµ„äº§è¡¨ - å­˜å‚¨å›¾ç‰‡ç´ æ",
                "required_columns": ["id", "project_id", "filename", "original_path"],
                "optional_columns": ["thumbnail_path", "mime_type", "file_size", "width", "height", "description", "tags", "color_palette", "processing_status", "processing_progress", "error_message", "created_at", "updated_at"]
            },
            "image_vectors": {
                "description": "å›¾ç‰‡å‘é‡è¡¨ - å­˜å‚¨å›¾ç‰‡å‘é‡æ•°æ®",
                "required_columns": ["id", "image_id", "vector_type", "vector_data"],
                "optional_columns": ["content_text", "model_version", "confidence_score", "vector_dimension", "created_at"]
            }
        }
        
        self.expected_indexes = [
            # æ ¸å¿ƒè¡¨ç´¢å¼•
            "idx_beats_project_id",
            "idx_beats_order_index", 
            "idx_assets_project_id",
            "idx_assets_processing_status",
            "idx_asset_vectors_asset_id",
            "idx_asset_vectors_content_type",
            
            # è§†é¢‘ç¼–è¾‘ç´¢å¼•
            "idx_timelines_project_id",
            "idx_clips_timeline_id",
            "idx_clips_order_index",
            "idx_render_tasks_timeline_id",
            "idx_render_tasks_status",
            
            # å›¾ç‰‡å¤„ç†ç´¢å¼•
            "idx_image_assets_project_id",
            "idx_image_vectors_image_id",
            
            # å¤åˆç´¢å¼•
            "idx_assets_project_status",
            "idx_beats_project_order"
        ]
    
    def connect_db(self) -> sqlite3.Connection:
        """è¿æ¥æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            return conn
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def get_existing_tables(self) -> List[str]:
        """è·å–ç°æœ‰è¡¨åˆ—è¡¨"""
        conn = self.connect_db()
        cursor = conn.cursor()
        
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
        tables = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        return tables
    
    def get_table_columns(self, table_name: str) -> List[Tuple[str, str]]:
        """è·å–è¡¨çš„åˆ—ä¿¡æ¯"""
        conn = self.connect_db()
        cursor = conn.cursor()
        
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [(row[1], row[2]) for row in cursor.fetchall()]  # (name, type)
        
        conn.close()
        return columns
    
    def get_existing_indexes(self) -> List[str]:
        """è·å–ç°æœ‰ç´¢å¼•åˆ—è¡¨"""
        conn = self.connect_db()
        cursor = conn.cursor()
        
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%'")
        indexes = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        return indexes
    
    def validate_table_structure(self) -> Dict:
        """éªŒè¯è¡¨ç»“æ„å®Œæ•´æ€§"""
        print("ğŸ” å¼€å§‹éªŒè¯æ•°æ®åº“è¡¨ç»“æ„...")
        
        results = {
            "total_expected": len(self.expected_tables),
            "total_existing": 0,
            "missing_tables": [],
            "existing_tables": [],
            "table_details": {},
            "overall_status": "unknown"
        }
        
        existing_tables = self.get_existing_tables()
        results["total_existing"] = len(existing_tables)
        results["existing_tables"] = existing_tables
        
        print(f"ğŸ“Š é¢„æœŸè¡¨æ•°é‡: {results['total_expected']}")
        print(f"ğŸ“Š ç°æœ‰è¡¨æ•°é‡: {results['total_existing']}")
        print()
        
        # æ£€æŸ¥æ¯ä¸ªé¢„æœŸçš„è¡¨
        for table_name, table_info in self.expected_tables.items():
            print(f"ğŸ” æ£€æŸ¥è¡¨: {table_name}")
            print(f"   æè¿°: {table_info['description']}")
            
            if table_name in existing_tables:
                print(f"   âœ… è¡¨å­˜åœ¨")
                
                # æ£€æŸ¥åˆ—ç»“æ„
                columns = self.get_table_columns(table_name)
                column_names = [col[0] for col in columns]
                
                table_result = {
                    "exists": True,
                    "columns": columns,
                    "missing_required_columns": [],
                    "missing_optional_columns": [],
                    "extra_columns": [],
                    "status": "ok"
                }
                
                # æ£€æŸ¥å¿…éœ€åˆ—
                for req_col in table_info["required_columns"]:
                    if req_col not in column_names:
                        table_result["missing_required_columns"].append(req_col)
                        print(f"   âŒ ç¼ºå°‘å¿…éœ€åˆ—: {req_col}")
                
                # æ£€æŸ¥å¯é€‰åˆ—
                for opt_col in table_info["optional_columns"]:
                    if opt_col not in column_names:
                        table_result["missing_optional_columns"].append(opt_col)
                        print(f"   âš ï¸  ç¼ºå°‘å¯é€‰åˆ—: {opt_col}")
                
                # æ£€æŸ¥é¢å¤–åˆ—
                all_expected_columns = table_info["required_columns"] + table_info["optional_columns"]
                for col_name in column_names:
                    if col_name not in all_expected_columns:
                        table_result["extra_columns"].append(col_name)
                        print(f"   â„¹ï¸  é¢å¤–åˆ—: {col_name}")
                
                # ç¡®å®šè¡¨çŠ¶æ€
                if table_result["missing_required_columns"]:
                    table_result["status"] = "error"
                elif table_result["missing_optional_columns"]:
                    table_result["status"] = "warning"
                else:
                    table_result["status"] = "ok"
                
                print(f"   ğŸ“‹ åˆ—æ•°é‡: {len(columns)}")
                print(f"   ğŸ“Š çŠ¶æ€: {table_result['status']}")
                
                results["table_details"][table_name] = table_result
                
            else:
                print(f"   âŒ è¡¨ä¸å­˜åœ¨")
                results["missing_tables"].append(table_name)
                results["table_details"][table_name] = {
                    "exists": False,
                    "status": "missing"
                }
            
            print()
        
        # ç¡®å®šæ•´ä½“çŠ¶æ€
        if results["missing_tables"]:
            results["overall_status"] = "error"
        elif any(t["status"] == "error" for t in results["table_details"].values()):
            results["overall_status"] = "error"
        elif any(t["status"] == "warning" for t in results["table_details"].values()):
            results["overall_status"] = "warning"
        else:
            results["overall_status"] = "ok"
        
        return results
    
    def validate_indexes(self) -> Dict:
        """éªŒè¯ç´¢å¼•å®Œæ•´æ€§"""
        print("ğŸ” å¼€å§‹éªŒè¯æ•°æ®åº“ç´¢å¼•...")
        
        existing_indexes = self.get_existing_indexes()
        
        results = {
            "total_expected": len(self.expected_indexes),
            "total_existing": len(existing_indexes),
            "missing_indexes": [],
            "existing_indexes": existing_indexes,
            "extra_indexes": []
        }
        
        print(f"ğŸ“Š é¢„æœŸç´¢å¼•æ•°é‡: {results['total_expected']}")
        print(f"ğŸ“Š ç°æœ‰ç´¢å¼•æ•°é‡: {results['total_existing']}")
        print()
        
        # æ£€æŸ¥ç¼ºå¤±çš„ç´¢å¼•
        for expected_index in self.expected_indexes:
            if expected_index not in existing_indexes:
                results["missing_indexes"].append(expected_index)
                print(f"âŒ ç¼ºå°‘ç´¢å¼•: {expected_index}")
            else:
                print(f"âœ… ç´¢å¼•å­˜åœ¨: {expected_index}")
        
        # æ£€æŸ¥é¢å¤–çš„ç´¢å¼•
        for existing_index in existing_indexes:
            if existing_index not in self.expected_indexes:
                results["extra_indexes"].append(existing_index)
                print(f"â„¹ï¸  é¢å¤–ç´¢å¼•: {existing_index}")
        
        return results
    
    def validate_data_integrity(self) -> Dict:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        print("ğŸ” å¼€å§‹éªŒè¯æ•°æ®å®Œæ•´æ€§...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        results = {
            "foreign_key_violations": [],
            "null_violations": [],
            "data_consistency_issues": [],
            "table_counts": {}
        }
        
        try:
            # æ£€æŸ¥è¡¨è®°å½•æ•°é‡
            existing_tables = self.get_existing_tables()
            for table in existing_tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                results["table_counts"][table] = count
                print(f"ğŸ“Š {table}: {count} æ¡è®°å½•")
            
            # æ£€æŸ¥å¤–é”®çº¦æŸï¼ˆå¦‚æœè¡¨å­˜åœ¨ï¼‰
            if "projects" in existing_tables and "beats" in existing_tables:
                cursor.execute("""
                    SELECT COUNT(*) FROM beats 
                    WHERE project_id NOT IN (SELECT id FROM projects)
                """)
                orphaned_beats = cursor.fetchone()[0]
                if orphaned_beats > 0:
                    results["foreign_key_violations"].append(f"beatsè¡¨ä¸­æœ‰{orphaned_beats}æ¡è®°å½•çš„project_idæ— æ•ˆ")
                    print(f"âŒ beatsè¡¨å¤–é”®è¿è§„: {orphaned_beats}æ¡")
                else:
                    print("âœ… beatsè¡¨å¤–é”®å®Œæ•´æ€§æ­£å¸¸")
            
            if "assets" in existing_tables and "asset_vectors" in existing_tables:
                cursor.execute("""
                    SELECT COUNT(*) FROM asset_vectors 
                    WHERE asset_id NOT IN (SELECT id FROM assets)
                """)
                orphaned_vectors = cursor.fetchone()[0]
                if orphaned_vectors > 0:
                    results["foreign_key_violations"].append(f"asset_vectorsè¡¨ä¸­æœ‰{orphaned_vectors}æ¡è®°å½•çš„asset_idæ— æ•ˆ")
                    print(f"âŒ asset_vectorsè¡¨å¤–é”®è¿è§„: {orphaned_vectors}æ¡")
                else:
                    print("âœ… asset_vectorsè¡¨å¤–é”®å®Œæ•´æ€§æ­£å¸¸")
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µçš„ç©ºå€¼
            if "projects" in existing_tables:
                cursor.execute("SELECT COUNT(*) FROM projects WHERE title IS NULL OR title = ''")
                null_titles = cursor.fetchone()[0]
                if null_titles > 0:
                    results["null_violations"].append(f"projectsè¡¨ä¸­æœ‰{null_titles}æ¡è®°å½•çš„titleä¸ºç©º")
                    print(f"âŒ projectsè¡¨titleå­—æ®µç©ºå€¼: {null_titles}æ¡")
                else:
                    print("âœ… projectsè¡¨titleå­—æ®µå®Œæ•´æ€§æ­£å¸¸")
            
        except Exception as e:
            print(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            results["error"] = str(e)
        finally:
            conn.close()
        
        return results
    
    def check_file_storage_paths(self) -> Dict:
        """æ£€æŸ¥æ–‡ä»¶å­˜å‚¨è·¯å¾„"""
        print("ğŸ” å¼€å§‹éªŒè¯æ–‡ä»¶å­˜å‚¨ç³»ç»Ÿ...")
        
        results = {
            "storage_directories": {},
            "missing_directories": [],
            "permission_issues": []
        }
        
        # é¢„æœŸçš„å­˜å‚¨ç›®å½•
        expected_dirs = [
            "assets",
            "assets/originals", 
            "assets/proxies",
            "assets/thumbnails",
            "assets/audio",
            "storage",
            "storage/renders",
            "storage/temp",
            "exports"
        ]
        
        for dir_path in expected_dirs:
            print(f"ğŸ” æ£€æŸ¥ç›®å½•: {dir_path}")
            
            if os.path.exists(dir_path):
                if os.path.isdir(dir_path):
                    # æ£€æŸ¥æƒé™
                    readable = os.access(dir_path, os.R_OK)
                    writable = os.access(dir_path, os.W_OK)
                    
                    results["storage_directories"][dir_path] = {
                        "exists": True,
                        "readable": readable,
                        "writable": writable,
                        "status": "ok" if readable and writable else "permission_issue"
                    }
                    
                    if readable and writable:
                        print(f"   âœ… ç›®å½•æ­£å¸¸ï¼Œå¯è¯»å†™")
                    else:
                        print(f"   âš ï¸  æƒé™é—®é¢˜ - å¯è¯»: {readable}, å¯å†™: {writable}")
                        results["permission_issues"].append(dir_path)
                else:
                    print(f"   âŒ è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•")
                    results["storage_directories"][dir_path] = {
                        "exists": False,
                        "status": "not_directory"
                    }
            else:
                print(f"   âŒ ç›®å½•ä¸å­˜åœ¨")
                results["missing_directories"].append(dir_path)
                results["storage_directories"][dir_path] = {
                    "exists": False,
                    "status": "missing"
                }
        
        return results
    
    def generate_report(self, table_results: Dict, index_results: Dict, 
                       integrity_results: Dict, storage_results: Dict) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„éªŒè¯æŠ¥å‘Š"""
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "database_path": self.db_path,
            "summary": {
                "overall_status": "unknown",
                "total_issues": 0,
                "critical_issues": 0,
                "warnings": 0
            },
            "table_structure": table_results,
            "indexes": index_results,
            "data_integrity": integrity_results,
            "file_storage": storage_results,
            "recommendations": []
        }
        
        # ç»Ÿè®¡é—®é¢˜
        critical_issues = 0
        warnings = 0
        
        # è¡¨ç»“æ„é—®é¢˜
        if table_results["missing_tables"]:
            critical_issues += len(table_results["missing_tables"])
        
        for table_detail in table_results["table_details"].values():
            if table_detail.get("status") == "error":
                critical_issues += len(table_detail.get("missing_required_columns", []))
            elif table_detail.get("status") == "warning":
                warnings += len(table_detail.get("missing_optional_columns", []))
        
        # ç´¢å¼•é—®é¢˜
        warnings += len(index_results["missing_indexes"])
        
        # æ•°æ®å®Œæ•´æ€§é—®é¢˜
        critical_issues += len(integrity_results["foreign_key_violations"])
        critical_issues += len(integrity_results["null_violations"])
        
        # å­˜å‚¨é—®é¢˜
        critical_issues += len(storage_results["missing_directories"])
        warnings += len(storage_results["permission_issues"])
        
        report["summary"]["critical_issues"] = critical_issues
        report["summary"]["warnings"] = warnings
        report["summary"]["total_issues"] = critical_issues + warnings
        
        # ç¡®å®šæ•´ä½“çŠ¶æ€
        if critical_issues > 0:
            report["summary"]["overall_status"] = "error"
        elif warnings > 0:
            report["summary"]["overall_status"] = "warning"
        else:
            report["summary"]["overall_status"] = "ok"
        
        # ç”Ÿæˆå»ºè®®
        if table_results["missing_tables"]:
            report["recommendations"].append("è¿è¡Œæ•°æ®åº“è¿ç§»è„šæœ¬åˆ›å»ºç¼ºå¤±çš„è¡¨")
        
        if index_results["missing_indexes"]:
            report["recommendations"].append("è¿è¡Œæ€§èƒ½ä¼˜åŒ–è„šæœ¬åˆ›å»ºç¼ºå¤±çš„ç´¢å¼•")
        
        if storage_results["missing_directories"]:
            report["recommendations"].append("åˆ›å»ºç¼ºå¤±çš„å­˜å‚¨ç›®å½•")
        
        if storage_results["permission_issues"]:
            report["recommendations"].append("ä¿®å¤å­˜å‚¨ç›®å½•çš„æƒé™é—®é¢˜")
        
        if integrity_results["foreign_key_violations"]:
            report["recommendations"].append("æ¸…ç†æ•°æ®åº“ä¸­çš„å¤–é”®çº¦æŸè¿è§„æ•°æ®")
        
        return report
    
    def run_full_validation(self) -> Dict:
        """è¿è¡Œå®Œæ•´çš„æ•°æ®åº“éªŒè¯"""
        print("=" * 60)
        print("ğŸ¬ PreVis PRO - æ•°æ®åº“ç»“æ„éªŒè¯")
        print("=" * 60)
        print(f"ğŸ“ æ•°æ®åº“è·¯å¾„: {self.db_path}")
        print()
        
        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.db_path):
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
            return {
                "error": "æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨",
                "database_path": self.db_path
            }
        
        try:
            # 1. éªŒè¯è¡¨ç»“æ„
            table_results = self.validate_table_structure()
            print()
            
            # 2. éªŒè¯ç´¢å¼•
            index_results = self.validate_indexes()
            print()
            
            # 3. éªŒè¯æ•°æ®å®Œæ•´æ€§
            integrity_results = self.validate_data_integrity()
            print()
            
            # 4. éªŒè¯æ–‡ä»¶å­˜å‚¨
            storage_results = self.check_file_storage_paths()
            print()
            
            # 5. ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report(table_results, index_results, 
                                        integrity_results, storage_results)
            
            return report
            
        except Exception as e:
            print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "error": str(e),
                "database_path": self.db_path
            }

def print_report_summary(report: Dict):
    """æ‰“å°æŠ¥å‘Šæ‘˜è¦"""
    print("=" * 60)
    print("ğŸ“‹ éªŒè¯æŠ¥å‘Šæ‘˜è¦")
    print("=" * 60)
    
    summary = report["summary"]
    status_emoji = {
        "ok": "âœ…",
        "warning": "âš ï¸ ",
        "error": "âŒ"
    }
    
    print(f"ğŸ¯ æ•´ä½“çŠ¶æ€: {status_emoji.get(summary['overall_status'], 'â“')} {summary['overall_status'].upper()}")
    print(f"ğŸ”¥ ä¸¥é‡é—®é¢˜: {summary['critical_issues']}")
    print(f"âš ï¸  è­¦å‘Š: {summary['warnings']}")
    print(f"ğŸ“Š æ€»é—®é¢˜æ•°: {summary['total_issues']}")
    print()
    
    if report.get("recommendations"):
        print("ğŸ’¡ å»ºè®®:")
        for i, rec in enumerate(report["recommendations"], 1):
            print(f"   {i}. {rec}")
        print()
    
    # è¯¦ç»†ç»Ÿè®¡
    table_results = report["table_structure"]
    print(f"ğŸ“‹ è¡¨ç»“æ„: {table_results['total_existing']}/{table_results['total_expected']} ä¸ªè¡¨å­˜åœ¨")
    
    if table_results["missing_tables"]:
        print(f"   âŒ ç¼ºå¤±è¡¨: {', '.join(table_results['missing_tables'])}")
    
    index_results = report["indexes"]
    print(f"ğŸ“Š ç´¢å¼•: {index_results['total_existing']}/{index_results['total_expected']} ä¸ªç´¢å¼•å­˜åœ¨")
    
    if index_results["missing_indexes"]:
        print(f"   âŒ ç¼ºå¤±ç´¢å¼•: {', '.join(index_results['missing_indexes'][:5])}")
        if len(index_results["missing_indexes"]) > 5:
            print(f"   ... è¿˜æœ‰ {len(index_results['missing_indexes']) - 5} ä¸ª")
    
    storage_results = report["file_storage"]
    total_dirs = len(storage_results["storage_directories"])
    missing_dirs = len(storage_results["missing_directories"])
    existing_dirs = total_dirs - missing_dirs
    print(f"ğŸ“ å­˜å‚¨ç›®å½•: {existing_dirs}/{total_dirs} ä¸ªç›®å½•å­˜åœ¨")
    
    if storage_results["missing_directories"]:
        print(f"   âŒ ç¼ºå¤±ç›®å½•: {', '.join(storage_results['missing_directories'])}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PreVis PRO æ•°æ®åº“ç»“æ„éªŒè¯å·¥å…·')
    parser.add_argument('--db-path', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', help='è¾“å‡ºæŠ¥å‘Šåˆ°JSONæ–‡ä»¶')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = DatabaseValidator(args.db_path)
    
    # è¿è¡ŒéªŒè¯
    report = validator.run_full_validation()
    
    if "error" in report:
        print(f"ğŸ’¥ éªŒè¯å¤±è´¥: {report['error']}")
        return 1
    
    # æ‰“å°æ‘˜è¦
    print_report_summary(report)
    
    # ä¿å­˜æŠ¥å‘Š
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    
    # è¿”å›çŠ¶æ€ç 
    if report["summary"]["overall_status"] == "error":
        return 1
    elif report["summary"]["overall_status"] == "warning":
        return 2
    else:
        return 0

if __name__ == "__main__":
    exit(main())